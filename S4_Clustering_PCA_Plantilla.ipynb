{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1EQ5G9rQcwE"
      },
      "source": [
        "# Clustering and PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Toc_OzXYQcwH"
      },
      "source": [
        "### Mushroom Dataset\n",
        "\n",
        "Podeis obtener el conjunto de datos en el siguiente enlace:\n",
        "\n",
        "[Mushroom Dataset](https://www.kaggle.com/uciml/mushroom-classification)\n",
        "\n",
        "Como podréis comprobar, hay muchas variables, todas ellas categóricas, por lo que exploraciones con scatterplot no nos serán útiles como en otros casos.\n",
        "\n",
        "La variable a predecir ``class`` es binaria.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJc845c11KbK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RWIOS2y_QcwH"
      },
      "outputs": [],
      "source": [
        "# Carga de librerías, las que hemos considerado básicas, añadid lo que queráis :)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ruta para guardar las tablas y reportes\n",
        "ruta='C:/4_F5/012_noSupervisado/Nat_noSupervisado/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Carga los datos del archivo CSV.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta al archivo CSV.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame con los datos cargados o None si hay un error.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener la ruta absoluta del archivo para evitar problemas con rutas relativas\n",
        "    abs_file_path = os.path.abspath(file_path)\n",
        "\n",
        "    # Verificar si el archivo existe en la ruta especificada\n",
        "    if not os.path.exists(abs_file_path):\n",
        "        # Imprimir mensajes de error detallados si el archivo no existe\n",
        "        print(f\"Error: El archivo no existe en la ruta: {abs_file_path}\")\n",
        "        print(f\"Directorio actual: {os.getcwd()}\")  # Mostrar el directorio actual para ayudar a depurar\n",
        "        print(\"Contenido del directorio:\")\n",
        "        try:\n",
        "            # Intentar listar el contenido del directorio para ayudar a identificar el problema\n",
        "            print(os.listdir(os.path.dirname(abs_file_path)))\n",
        "        except FileNotFoundError:\n",
        "            print(\"El directorio no existe.\")  # Informar si el directorio tampoco existe\n",
        "        return None  # Devolver None para indicar que la carga falló\n",
        "\n",
        "    try:\n",
        "        # Intentar cargar los datos utilizando pandas\n",
        "        df = pd.read_csv(abs_file_path)\n",
        "        print(f\"Datos cargados exitosamente. Shape: {df.shape}\")  # Confirmar la carga exitosa\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        # Capturar cualquier excepción que ocurra durante la carga e imprimir un mensaje de error\n",
        "        print(f\"Error al cargar los datos: {e}\")\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bloque de ejemplo de uso (solo se ejecuta si el script se ejecuta directamente)\n",
        "if __name__ == \"__main__\":\n",
        "    # Obtener la ruta al archivo CSV dentro de la estructura del proyecto\n",
        "    #script_dir = os.path.dirname(os.path.abspath(__file__)) #sólo sirve cuando es .py porque la variable __file__ no está disponible porque no se está ejecutando un script de Python directamente.\n",
        "    #project_root = os.path.dirname(os.path.dirname(script_dir))\n",
        "    #data_path = os.path.join(project_root, \"data\", \"mushrooms.csv\") #(project_root,\"carpeta\",\"subcarpeta\",\"archivo.csv\")\n",
        "    data_path = data_path = os.path.join(os.getcwd(), \"data\", \"mushrooms.csv\")\n",
        "\n",
        "    print(f\"Intentando cargar el archivo desde: {data_path}\")\n",
        "\n",
        "\n",
        "    # Llamar a la función load_data para cargar los datos\n",
        "    \n",
        "    df = load_data(data_path)\n",
        "    if df is not None:\n",
        "        # Imprimir las primeras filas del DataFrame si la carga fue exitosa\n",
        "        print(df.head())\n",
        "    else:\n",
        "        # Imprimir un mensaje de error si la carga falló\n",
        "        print(\"No se pudieron cargar los datos. Verifica la ruta del archivo y su existencia.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KbJPDrpQcwI"
      },
      "source": [
        "### Leer conjunto de datos y primer vistazo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFJoAIsVQcwI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Leer el csv y sacar por pantalla las cinco primeras filas.\n",
        "\n",
        "def lectura_csv(df):\n",
        "    return df.head()\n",
        "print(lectura_csv(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La librería OS nos permite navegar entre los directorios del sistema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dePM9qXKQcwJ"
      },
      "source": [
        "### Exploración de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45TsUuwkQcwJ"
      },
      "outputs": [],
      "source": [
        "# Descripción del conjunto de datos, estándard.\n",
        "\n",
        "\n",
        "print(df.describe(include='object').T) # con el parámetro include='object' para obtener estadísticas descriptivas para las columnas categóricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJG-fxzJQcwJ"
      },
      "outputs": [],
      "source": [
        "# Información sobre el tipo de datos de cada feature.\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xXz4mT0QcwJ",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "print(f'El número de filas del dataset es:\\n{df.shape[0]:,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Igual que otras veces, una linea, contar los nulos por variable.\n",
        "def count_missing(df):\n",
        "    missing_values = df.isnull().sum()\n",
        "    if (missing_values == 0).all():\n",
        "        return \"El conteo por columna de valores 'missing' resulta 0. Es decir, no hay valores 'missing'\"\n",
        "    else:\n",
        "        return missing_values\n",
        "\n",
        "print(count_missing(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#---- Verifica si hay columnas duplicadas\n",
        "duplicated_cols = df.columns[df.columns.duplicated()]\n",
        "\n",
        "if len(duplicated_cols) > 0:\n",
        "    print(\"Columnas duplicadas:\", duplicated_cols)\n",
        "else:\n",
        "    print(\"No hay columnas duplicadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "    print(df[col].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Crear una figura con múltiples subplots\n",
        "fig, axs = plt.subplots(nrows=23, ncols=1, figsize=(8, 60))\n",
        "\n",
        "# Iterar sobre cada variable y crear un gráfico de barras\n",
        "for i, variable in enumerate(df.columns):\n",
        "    sns.countplot(x=variable, data=df, ax=axs[i])\n",
        "    axs[i].set_title(f'Distribución de {variable}')\n",
        "\n",
        "# Ajustar el layout para que los títulos no se superpongan\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Considero que valores 'outliers' son aquellos que suponen un 1% del total de registros\n",
        "for col in df.columns:\n",
        "    print(df[col].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJv-ez3WQcwK"
      },
      "source": [
        "#### Buscar valores extraños. Para ello, ver los valores únicos en cada feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUZ2EHmTQcwK"
      },
      "outputs": [],
      "source": [
        "# Obtener un nuevo dataframe de dos columnas donde en la primera estén las features (features) y en la otra los valores únicos\n",
        "# asociados (n_values).\n",
        "\n",
        "values_unique=pd.DataFrame({'categories':df.nunique()})\n",
        "print(values_unique)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXIyz_tdQcwK"
      },
      "source": [
        "#### Tratar aquellos valores que entendamos que sean nulos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "OVQnxK1gQcwK"
      },
      "outputs": [],
      "source": [
        "# Imputaciones. Podéis quitar esos puntos (fila entera), imputar con la moda o dejar ese valor como una posibilidad más."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dbmx1Z7QcwK"
      },
      "source": [
        "#### Mirad cuántos valores hay en cada feature, ¿Todas las features aportan información? Si alguna no aporta información, eliminadla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts2xeUavQcwK"
      },
      "outputs": [],
      "source": [
        "# Dejar por el camino si procede.\n",
        "#Diluyo el df para que se expanda cada features según su categoría\n",
        "melted_df = pd.melt(df, var_name='Features', value_name='Categories')\n",
        "grouped_df = melted_df.groupby(['Features', 'Categories']).size().reset_index(name='count_values')\n",
        "\n",
        "category_totals = grouped_df.groupby('Features')['count_values'].transform('sum')\n",
        "#machaco la variable\n",
        "grouped_df['ratio']=round((grouped_df['count_values'] / category_totals ),2)\n",
        "print(grouped_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_df.to_csv(ruta+'tables/df_grouped.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Voy a filtrar el dataframe agrupado para que --> ¿Qué hago con los ?\n",
        "#count = (grouped_df['ratio'] < 0.01).sum()\n",
        "under_one = grouped_df[grouped_df['ratio'] < 0.01]\n",
        "print(f\"Valores menores a 0.01 en la columna 'ratio': {(grouped_df['ratio'] < 0.01).sum()}\")\n",
        "print(under_one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dX1LM1VQcwK"
      },
      "source": [
        "#### Separar entre variables predictoras y variables a predecir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS9HEA2eQcwK"
      },
      "outputs": [],
      "source": [
        "# La variable que trata de predecir este conjunto de datos es 'class'.\n",
        "# Por tanto la variable objetivo es 'y'\n",
        "# las variables predictoras son las columnas son 'x'\n",
        "y = df['class']\n",
        "print(y.head())\n",
        "x =df.drop(columns='class')\n",
        "\n",
        "print(x.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "########## Hago ingeniería de características?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### Miro la correlación entre las variables predictoras para ello hay que codificar primero, pero es mejor para variables cuantitativas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN1fZZfZQcwL"
      },
      "source": [
        "#### Codificar correctamente las variables categóricas a numéricas\n",
        "\n",
        "----> Creo que es error\n",
        "\n",
        " One Hot Encoder necesita ver toda la información de las variables categóricas en X para codificarlas correctamente. Si aplicas el One Hot Encoder después de dividir X en X_train y X_test, podrías perder información importante y obtener resultados inconsistentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4l92dfEQcwL"
      },
      "outputs": [],
      "source": [
        "# One Hot Encoder (una linea).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBBAM0bzQcwL"
      },
      "source": [
        "#### Train test split\n",
        "\n",
        "----> la codificación de etiquetas debe realizarse después de la partición de los datos en conjuntos de train y test, ya que de lo contrario se podría producir un problema de \"fuga de datos\" (data leakage), donde el modelo se beneficia de información que no debería tener acceso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHxqeJQqQcwL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Os lo dejamos a todos igual\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "\n",
        "print(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Me resulta demasiadas columnas, voy a ver si con Label. Label no, porque aporta 'ordinalidad'\n",
        "\"\"\" \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "x_train_lab=le.fit_transform(x_train.values)\n",
        "x_test_lab=le.transform(x_test.values) # se garantiza que el modelo no tenga acceso a información que no debería tener y que las categorías se asignen de manera consistente en ambos conjuntos de datos.\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "De la siguiente manera, puedes asegurarte de que la codificación one-hot se aplique de manera consistente a ambos conjuntos de datos, y que el modelo de codificación se ajuste solo a los datos de entrenamiento.\n",
        "\n",
        "Hay que recordar que, si no separamos los conjuntos de datos antes de la codificación, podríamos estar introduciendo sesgo en el modelo, ya que el conjunto de prueba podría influir en la codificación one-hot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Aplicar One Hot Encoder a X\n",
        "ohe = OneHotEncoder(handle_unknown='ignore') #\n",
        "ohe_ajuste=ohe.fit_transform(x_train) # se ajusta el modelo de codificación para que sepa cómo codificar las categorías presentes en el conjunto de entrenamiento (train)\n",
        "x_train_encoded =ohe.transform(x_train) #se aplica la codificación ajustada en fit al conjunto de entrenamiento (train)\n",
        "\n",
        "x_test_encoded= ohe.transform(x_test) #se aplica la codificación ajustada en fit al conjunto de test \n",
        "\n",
        "\n",
        "# Convierte la matriz de salida en un dataframe\n",
        "df_x_train_enc = pd.DataFrame(x_train_encoded.toarray(), columns=ohe.get_feature_names_out())\n",
        "df_x_test_enc = pd.DataFrame(x_test_encoded.toarray(), columns=ohe.get_feature_names_out())\n",
        "\n",
        "print(df_x_train_enc)\n",
        "print(df_x_test_enc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sL57bzCQcwL"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#La matriz de correlación puede no ser la mejor opción para analizar la relación entre variables categóricas. En su lugar, podrías utilizar métricas de asociación como la chi-cuadrado o la métrica de información mutua para analizar la relación entre variables categóricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#La reducción de dimensionalidad mediante PCA asume una distrución normal de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhAhJqbKQcwM"
      },
      "source": [
        "Es un conjunto de datos del que aún no hemos visto nada (no tenemos graficas) así que vamos a hacer algunas. Tenemos el problema de que son muchas variables, **PCA al rescate**: le pedimos que nos de dos dimensiones y las pintamos, sabemos que serán **aquellas que retengan más información**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3232KSn9QcwM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.90)      # metodo de sklearn\n",
        "pca.fit(x_train_encoded) # método fit solo ajusta los parámetros del modelo PCA según los datos de entrenamiento\n",
        "\n",
        "\n",
        "# Aplicar la transformación PCA a ambos conjuntos de datos\n",
        "x_train_pca = pca.transform(x_train_encoded)\n",
        "x_test_pca = pca.transform(x_test_encoded)\n",
        "pd.DataFrame(x_test_encoded.toarray(), columns=ohe.get_feature_names_out())\n",
        "\n",
        "df_x_train_pca=pd.DataFrame(x_train_pca.toarray(), columns=pca.get_feature_names_out())\n",
        "print(df_x_train_pca)\n",
        "# Representar en un scatterplot y poner en color las etiquetas de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMYH_Hv0QcwM"
      },
      "source": [
        "Parece que está bastante separadito, parece que a ojo mucho se puede ver :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdE0AvlKQcwM"
      },
      "source": [
        "Igualmente, vamos a entrenar un clasificador a ver qué tal lo hace antes de editar más"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKQqz_EPQcwM"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 1. Definir el clasificador y el número de estimadores\n",
        "# 2. Entrenar en train\n",
        "# 3. Calcular la precisión sobre test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PACQlU5_QcwM"
      },
      "source": [
        "Es un conjunto sencillo y Random Forest es muy bueno en su trabajo, Igualmente, vamos a ver qué tamaño tenemos de dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODibK0D2QcwN"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rEVhvRaQcwN"
      },
      "source": [
        "¿Muchas features no? Vamos a reducir las usando PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEJPZw_cQcwN",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "n_features = # definir un rango de valores a probar\n",
        "scores = []\n",
        "\n",
        "for n in n_features:\n",
        "\n",
        "    # Hacer PCA sobre X_train\n",
        "    # 1. Definir PCA\n",
        "    # 2. Aprender PCA sobre X_train\n",
        "\n",
        "    # Entrenar Random Forest\n",
        "    # 1. Definir el RF\n",
        "    # 2. Entrenar clasificador\n",
        "\n",
        "    # Guardar el score\n",
        "\n",
        "\n",
        "sns.lineplot(x=n_features, y=scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKjl6aHiQcwN"
      },
      "source": [
        "Vale, estamos viendo que a partir de unas 10 features ya tenemos el score que queríamos y además hemos reducido las variables a un 10% de las que teníamos, incluso menos que las variables originales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jvqa-leQcwN"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWiMHKUdQcwN"
      },
      "source": [
        "Viendo que el conjunto de datos es sencillito, podemos intentar hacer algo de clustering a ver qué información podemos obtener.\n",
        "\n",
        "El primer paso va a ser importar la función de Kmeans de sklearn, y a partir de ahi, vamos a buscar el valor óptimo de clusters. Como hemos visto anteriormente, este valor lo obtenemos, por ejemplo, del codo de la gráfica que representa el total de las distancias de los puntos a los centros de los clusters asociados. Os dejo la página de la documentación de sklearn para que lo busquéis:\n",
        "\n",
        "[K-Means on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
        "\n",
        "Con esto solo hay que ahora generar los modelos de kmeans, evaluar y pintar la gráfica para los valores de ``k`` que establezcais.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DV0IXFncQcwO"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "scores = []\n",
        "k_values = # definir un rango\n",
        "for a in k_values:\n",
        "\n",
        "    # Definir Kmeans y ajustar\n",
        "    # Guardar la predicción\n",
        "\n",
        "sns.lineplot(x=k_values, y=scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSgPG286QcwO"
      },
      "source": [
        "Con el valor que hayáis obtenido de la gráfica, podéis obtener una buena aproximación de Kmeans y con ello podemos pasar a explorar cómo de bien han separado la información los distintos clusters. Para ello, se va a hacer un ``catplot``, seaborn os lo hará solito. Con esto lo que se pretende ver es la distribución de la varaible a predecir en función del cluster que haya determinado Kmeans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa7XfETyQcwO",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Aprender Kmeans con el valor de K obtenido.\n",
        "\n",
        "kmeans = # Definir y entrenar Kmeans.\n",
        "\n",
        "# Preparar el catplot.\n",
        "\n",
        "\n",
        "# Pintar.\n",
        "ax = sns.catplot(col=, x=, data=, kind='count',col_wrap=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzMUKFwzQcwO"
      },
      "source": [
        "Vamos a ver qué tal queda esto pintado. Para ello, repetimos el scatterplot de antes pero usando como color el cluster asignado por kmeans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjhjuexcQcwO",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Entrenar PCA para representar.\n",
        "\n",
        "# Usar un color por cada cluster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0q-ZDhQQcwO"
      },
      "source": [
        "¿Es bastante parecido no? No es tan bueno como el Random Forest, pero ha conseguido identificar bastante bien los distintos puntos del dataset sin utilizar las etiquetas. De hecho, el diagrama de factor que hemos visto antes muestra que solo un par de clusters son imprecisos. Si no hubieramos tenido etiquetas esta aproximacion nos hubiera ayudado mucho a clasificar los distintos tipos de hongos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
